# ollama-openwebui-docker
A very simple integration to run ollama and open-webui together locally using Docker

## What do you need to run the system?
 Just install [Docker](https://www.docker.com/) and [Docker compose](https://docs.docker.com/compose/), clone this repo and type:

     cd ollama-openwebui-docker
     docker compose up -d

## Ollama
It is the easiest way to run LLMs locally. Please check [the official website for more information and documentation](https://ollama.com/).

## Open-WebUI
It is one of the most important and complete open source web UIs out there to manage and interact with the LLMs run by Ollama. For more information and documentatio, please check [the official website](https://openwebui.com/)

> It is necessary to create an account before using open-webUI